# Self-Play Training Loop - Iteration 1 Config
model_name_or_path: "checkpoints/sft_p2_aggressive_lingshu/merged"
backend: "transformers"

# Trajectory collection
domains:
  - clinical_diagnosis
  - medical_qa
  - drug_interaction
  - ehr_management
tasks_per_domain: 15
max_turns: 15
temperature: 0.7
num_trajectories_per_task: 1

# Quality filtering
quality_threshold: 0.45
use_llm_judge: false  # Use heuristic for speed in iter 1
judge_model: "self"

# Training
training_method: "sft"
lora_r: 16
lora_target_modules:
  - q_proj
  - k_proj
  - v_proj
  - o_proj
learning_rate: 1.0e-5
num_train_epochs: 2
batch_size: 2
gradient_accumulation_steps: 8

# Iteration control
max_iterations: 1  # Just 1 iteration for now
eval_every: 1
min_trajectories_for_training: 20

# Paths
output_dir: "checkpoints/self_play"
log_dir: "logs/self_play"
trajectory_dir: "datasets/self_play_trajectories"
